{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFB67GpiB68I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a76ca41-2017-481e-aed6-f37943bdfbc8"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
        "from keras.layers import Flatten, Dense, Dropout,BatchNormalization\n",
        "from keras.layers import Input, concatenate\n",
        "from keras.models import Model,load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import plot_model,np_utils\n",
        "from keras import regularizers\n",
        "import keras.metrics as metric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMlfs0PHBs_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#設定好數值，LEARNING_RATE、MOMENTUM以提高準確率，DROPOUT、WEIGHT_DECAY降低overfitting發生的機率，LRN2D_NORM將局部影響歸一化變一層，DATA_FORMAT='channels_last'確認資料輸入方式為(batch, steps, features)，USE_BN=True可以有效的控制參數初始化\n",
        "NB_CLASS=8\n",
        "LEARNING_RATE=0.01\n",
        "MOMENTUM=0.9\n",
        "DROPOUT=0.4\n",
        "WEIGHT_DECAY=0.0005\n",
        "LRN2D_NORM=True\n",
        "DATA_FORMAT='channels_last'\n",
        "USE_BN=True\n",
        "\n",
        "#導入資料集，用了訓練集，驗證集，測試集，比例為8:1:1。 \n",
        "train_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'\n",
        "vaildation_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetvaildation'\n",
        "test_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTest'\n",
        "\n",
        "IM_WIDTH=114\n",
        "IM_HEIGHT=114\n",
        "batch_size=400\n",
        "EPOCH= 25\n",
        "#導入ImageDataGenrator增強數據集，可以旋轉圖片，水平翻轉、旋轉角度、錯切變換、圖片長寬方向進行放大、水平位置和上下位置的平移\n",
        "\n",
        "#train data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    featurewise_center=True\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_root,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        ")\n",
        "\n",
        "#vaild data\n",
        "vaild_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    featurewise_center=True\n",
        ")\n",
        "vaild_generator = train_datagen.flow_from_directory(\n",
        "  vaildation_root,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        ")\n",
        "\n",
        "#test data\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    featurewise_center=True\n",
        ")\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "  test_root,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        ")\n",
        "\n",
        "#將資料壓扁特徵標準化，存入個別特定區間\n",
        "def conv2D_lrn2d(x,filters,kernel_size,strides=(1,1),padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=WEIGHT_DECAY):\n",
        "\n",
        "    if weight_decay:\n",
        "        kernel_regularizer=regularizers.l2(weight_decay)\n",
        "        bias_regularizer=regularizers.l2(weight_decay)\n",
        "    else:\n",
        "        kernel_regularizer=None\n",
        "        bias_regularizer=None\n",
        "\n",
        "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
        "\n",
        "    if lrn2d_norm:\n",
        "        x=BatchNormalization()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#主程式，模型建立\n",
        "def inception_module(x,params,concat_axis,padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=None):\n",
        "    (branch1,branch2,branch3,branch4)=params\n",
        "    if weight_decay:\n",
        "        kernel_regularizer=regularizers.l2(weight_decay)\n",
        "        bias_regularizer=regularizers.l2(weight_decay)\n",
        "    else:\n",
        "        kernel_regularizer=None\n",
        "        bias_regularizer=None\n",
        "    #1x1\n",
        "    pathway1=Conv2D(filters=branch1[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
        "\n",
        "    #1x1->3x3\n",
        "    pathway2=Conv2D(filters=branch2[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
        "    pathway2=Conv2D(filters=branch2[1],kernel_size=(3,3),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway2)\n",
        "\n",
        "    #1x1->5x5\n",
        "    pathway3=Conv2D(filters=branch3[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
        "    pathway3=Conv2D(filters=branch3[1],kernel_size=(5,5),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway3)\n",
        "\n",
        "    #3x3->1x1\n",
        "    pathway4=MaxPooling2D(pool_size=(3,3),strides=1,padding=padding,data_format=DATA_FORMAT)(x)\n",
        "    pathway4=Conv2D(filters=branch4[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway4)\n",
        "\n",
        "    return concatenate([pathway1,pathway2,pathway3,pathway4],axis=concat_axis)\n",
        "\n",
        "#我們使用了四個層數\n",
        "def create_model():\n",
        "    if DATA_FORMAT=='channels_first':\n",
        "        INP_SHAPE=(3,114,114)\n",
        "        img_input=Input(shape=INP_SHAPE)\n",
        "        CONCAT_AXIS=1\n",
        "    elif DATA_FORMAT=='channels_last':\n",
        "        INP_SHAPE=(114,114,3)\n",
        "        img_input=Input(shape=INP_SHAPE)\n",
        "        CONCAT_AXIS=3\n",
        "    else:\n",
        "        raise Exception('Invalid Dim Ordering')\n",
        "\n",
        "    x=conv2D_lrn2d(img_input,64,(5,5),2,padding='same',lrn2d_norm=False)\n",
        "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "\n",
        "    x=conv2D_lrn2d(x,64,(1,1),1,padding='same',lrn2d_norm=False)\n",
        "\n",
        "    x=conv2D_lrn2d(x,192,(3,3),1,padding='same',lrn2d_norm=True)\n",
        "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
        "\n",
        "    x=inception_module(x,params=[(64,),(96,128),(16,32),(32,)],concat_axis=CONCAT_AXIS) \n",
        "    x=inception_module(x,params=[(128,),(128,192),(32,96),(64,)],concat_axis=CONCAT_AXIS) \n",
        "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
        "\n",
        "    \n",
        "\n",
        "    x=Flatten()(x)\n",
        "    x=Dropout(DROPOUT)(x)\n",
        "    x=Dense(NB_CLASS,activation='linear')(x)\n",
        "    x=Dense(NB_CLASS,activation='softmax')(x)\n",
        "\n",
        "    return x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT\n",
        "\n",
        "\n",
        "def check_print():\n",
        "    #創造模型\n",
        "    x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT=create_model()\n",
        "\n",
        "    #創造一個 Keras 模型\n",
        "    model=Model(inputs=img_input,outputs=[x])\n",
        "    \n",
        "    \n",
        "# 檢視神經網路\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc',metric.top_k_categorical_accuracy])\n",
        "    return model\n",
        "\n",
        "if _name__=='__main_':\n",
        "    if os.path.exists('inception_1.h5'):\n",
        "        model=load_model('inception_1.h5')\n",
        "    else:\n",
        "        model=check_print()\n",
        "\n",
        "    model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
        "                        ,validation_steps=vaild_generator.n/batch_size)\n",
        "    model.save('inception_1.h5')\n",
        "    model.metrics=['acc',metric.top_k_categorical_accuracy]\n",
        "    loss,acc,top_acc=model.evaluate_generator(test_generator,steps=test_generator.n/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSHCqYgfB6-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ov7IOh3B7Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}